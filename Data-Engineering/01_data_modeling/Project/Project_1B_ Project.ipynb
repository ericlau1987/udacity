{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data-engineering/01_data_modeling/Project\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "try: \n",
    "    cluster = Cluster(['cassandra-seed'], port=9042) #If you have a locally installed Apache Cassandra instance\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Create a Keyspace \n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS events \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 3 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Set KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace('events')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cassandra_dataframe:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df \n",
    "        self.columns = self.df.columns\n",
    "        self.dtypes = self.df.dtypes\n",
    "        self.cluster = None \n",
    "        self.session = None\n",
    "        # self.__connect_cassandra()\n",
    "\n",
    "    def connect_cassandra(self):\n",
    "        from cassandra.cluster import Cluster\n",
    "        try: \n",
    "            self.cluster = Cluster(['cassandra-seed'], port=9042) #If you have a locally installed Apache Cassandra instance\n",
    "            self.session = self.cluster.connect()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def create_cassandra_keyspace(self, keyspace:str):\n",
    "        # TO-DO: Create a Keyspace \n",
    "        try:\n",
    "            query = f\"CREATE KEYSPACE IF NOT EXISTS {keyspace} \"\n",
    "            query += \"\"\"WITH REPLICATION = \n",
    "            { 'class' : 'SimpleStrategy', 'replication_factor' : 3 }\"\"\"\n",
    "            self.session.execute(query)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        # print(query)\n",
    "    \n",
    "    def set_cassandra_keysapce(self, keyspace):\n",
    "        # TO-DO: Set KEYSPACE to the keyspace specified above\n",
    "        try:\n",
    "            self.session.set_keyspace('events')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def __drop_cassandra_table(self, table_name:str):\n",
    "        query = f\"DROP TABLE IF EXISTS {table_name}\"\n",
    "        try:\n",
    "            self.session.execute(query)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def __get_df_column_name(self):\n",
    "        return (', ').join(self.df.columns)\n",
    "\n",
    "    def __set_column_type(self, pk:list):\n",
    "        res = []\n",
    "        for col, Dtype in zip(self.df.dtypes.index, self.df.dtypes.values):\n",
    "\n",
    "            Dtype_mapping = {\n",
    "                'object': 'text',\n",
    "                'float64': 'float',\n",
    "                'int64': 'int'\n",
    "            }\n",
    "            data_type = Dtype_mapping[str(Dtype)]\n",
    "            res.append(f'{col} {data_type}')\n",
    "        if pk:\n",
    "            res.append(f\"PRIMARY KEY ({(', ').join(pk)})\")\n",
    "        return (', ').join(res)\n",
    "\n",
    "    def create_cassandra_table(self, table_name:str, pk:list, drop_table_first:bool=False):\n",
    "        if drop_table_first:\n",
    "           self. __drop_cassandra_table()\n",
    "        query = f\"CREATE TABLE IF NOT EXISTS {table_name} \"\n",
    "        query = query + f\"({self.__set_column_type(pk)})\"\n",
    "        try:\n",
    "            self.session.execute(query)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def insert_df_2_cassandra_table(self, table_name):\n",
    "        columns = self.__get_df_column_name()\n",
    "        for key, row in self.df.iterrows():\n",
    "            query = f\"insert into {table_name} ({columns})\"\n",
    "            insert_values_query = f\" VALUES ({(', ').join(['%s']*len(self.df.columns))})\"\n",
    "            query = query + insert_values_query\n",
    "            res =[]\n",
    "            for key, value in enumerate(row):\n",
    "                if data[data.columns[key]].dtype == np.dtype('O'):\n",
    "                    res.append(value)\n",
    "                elif data[data.columns[key]].dtype == np.dtype('float64'):\n",
    "                    res.append(float(value))\n",
    "                elif data[data.columns[key]].dtype == np.dtype('int64'):\n",
    "                    res.append(int(value))\n",
    "                else:\n",
    "                    res.append(value)\n",
    "            self.session.execute(query, res)\n",
    "    \n",
    "    def cassandra_query_2_df(self, query):\n",
    "        from cassandra.query import dict_factory\n",
    "        try:\n",
    "            session.row_factory = dict_factory\n",
    "            rows = session.execute(query)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        res = {}\n",
    "        if rows:\n",
    "            for key in rows.one().keys():\n",
    "                res[key] = []\n",
    "\n",
    "        for row in rows:\n",
    "            for key, value in row.items():\n",
    "                res[key].append(value)\n",
    "\n",
    "        return pd.DataFrame.from_dict(res)\n",
    "        # return res\n",
    "\n",
    "    def close_connection(self):\n",
    "        self.session.shutdown()\n",
    "        self.cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionid</th>\n",
       "      <th>iteminsession</th>\n",
       "      <th>artist</th>\n",
       "      <th>firstname</th>\n",
       "      <th>gender</th>\n",
       "      <th>lastname</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>song</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>Regina Spektor</td>\n",
       "      <td>Layla</td>\n",
       "      <td>F</td>\n",
       "      <td>Griffin</td>\n",
       "      <td>191.085266</td>\n",
       "      <td>paid</td>\n",
       "      <td>Lake Havasu City-Kingman, AZ</td>\n",
       "      <td>The Calculation (Album Version)</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Octopus Project</td>\n",
       "      <td>Layla</td>\n",
       "      <td>F</td>\n",
       "      <td>Griffin</td>\n",
       "      <td>250.957916</td>\n",
       "      <td>paid</td>\n",
       "      <td>Lake Havasu City-Kingman, AZ</td>\n",
       "      <td>All Of The Champs That Ever Lived</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>Tegan And Sara</td>\n",
       "      <td>Layla</td>\n",
       "      <td>F</td>\n",
       "      <td>Griffin</td>\n",
       "      <td>180.061584</td>\n",
       "      <td>paid</td>\n",
       "      <td>Lake Havasu City-Kingman, AZ</td>\n",
       "      <td>So Jealous</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>Dragonette</td>\n",
       "      <td>Layla</td>\n",
       "      <td>F</td>\n",
       "      <td>Griffin</td>\n",
       "      <td>153.390564</td>\n",
       "      <td>paid</td>\n",
       "      <td>Lake Havasu City-Kingman, AZ</td>\n",
       "      <td>Okay Dolores</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>Lil Wayne / Eminem</td>\n",
       "      <td>Layla</td>\n",
       "      <td>F</td>\n",
       "      <td>Griffin</td>\n",
       "      <td>229.589752</td>\n",
       "      <td>paid</td>\n",
       "      <td>Lake Havasu City-Kingman, AZ</td>\n",
       "      <td>Drop The World</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815</th>\n",
       "      <td>986</td>\n",
       "      <td>1</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>Aiden</td>\n",
       "      <td>M</td>\n",
       "      <td>Hess</td>\n",
       "      <td>240.064850</td>\n",
       "      <td>free</td>\n",
       "      <td>La Crosse-Onalaska, WI-MN</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>986</td>\n",
       "      <td>2</td>\n",
       "      <td>Iron And Wine</td>\n",
       "      <td>Aiden</td>\n",
       "      <td>M</td>\n",
       "      <td>Hess</td>\n",
       "      <td>153.050980</td>\n",
       "      <td>free</td>\n",
       "      <td>La Crosse-Onalaska, WI-MN</td>\n",
       "      <td>Naked As We Can</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>986</td>\n",
       "      <td>3</td>\n",
       "      <td>The xx</td>\n",
       "      <td>Aiden</td>\n",
       "      <td>M</td>\n",
       "      <td>Hess</td>\n",
       "      <td>158.249344</td>\n",
       "      <td>free</td>\n",
       "      <td>La Crosse-Onalaska, WI-MN</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>986</td>\n",
       "      <td>4</td>\n",
       "      <td>The Antlers</td>\n",
       "      <td>Aiden</td>\n",
       "      <td>M</td>\n",
       "      <td>Hess</td>\n",
       "      <td>328.881195</td>\n",
       "      <td>free</td>\n",
       "      <td>La Crosse-Onalaska, WI-MN</td>\n",
       "      <td>Epilogue</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6819</th>\n",
       "      <td>986</td>\n",
       "      <td>5</td>\n",
       "      <td>Fattburger</td>\n",
       "      <td>Aiden</td>\n",
       "      <td>M</td>\n",
       "      <td>Hess</td>\n",
       "      <td>217.207703</td>\n",
       "      <td>free</td>\n",
       "      <td>La Crosse-Onalaska, WI-MN</td>\n",
       "      <td>Groovin'</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6820 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sessionid  iteminsession              artist firstname gender lastname  \\\n",
       "0            23              0      Regina Spektor     Layla      F  Griffin   \n",
       "1            23              1     Octopus Project     Layla      F  Griffin   \n",
       "2            23              2      Tegan And Sara     Layla      F  Griffin   \n",
       "3            23              3          Dragonette     Layla      F  Griffin   \n",
       "4            23              4  Lil Wayne / Eminem     Layla      F  Griffin   \n",
       "...         ...            ...                 ...       ...    ...      ...   \n",
       "6815        986              1        Jack Johnson     Aiden      M     Hess   \n",
       "6816        986              2       Iron And Wine     Aiden      M     Hess   \n",
       "6817        986              3              The xx     Aiden      M     Hess   \n",
       "6818        986              4         The Antlers     Aiden      M     Hess   \n",
       "6819        986              5          Fattburger     Aiden      M     Hess   \n",
       "\n",
       "          length level                      location  \\\n",
       "0     191.085266  paid  Lake Havasu City-Kingman, AZ   \n",
       "1     250.957916  paid  Lake Havasu City-Kingman, AZ   \n",
       "2     180.061584  paid  Lake Havasu City-Kingman, AZ   \n",
       "3     153.390564  paid  Lake Havasu City-Kingman, AZ   \n",
       "4     229.589752  paid  Lake Havasu City-Kingman, AZ   \n",
       "...          ...   ...                           ...   \n",
       "6815  240.064850  free     La Crosse-Onalaska, WI-MN   \n",
       "6816  153.050980  free     La Crosse-Onalaska, WI-MN   \n",
       "6817  158.249344  free     La Crosse-Onalaska, WI-MN   \n",
       "6818  328.881195  free     La Crosse-Onalaska, WI-MN   \n",
       "6819  217.207703  free     La Crosse-Onalaska, WI-MN   \n",
       "\n",
       "                                   song  userid  \n",
       "0       The Calculation (Album Version)      24  \n",
       "1     All Of The Champs That Ever Lived      24  \n",
       "2                            So Jealous      24  \n",
       "3                          Okay Dolores      24  \n",
       "4                        Drop The World      24  \n",
       "...                                 ...     ...  \n",
       "6815                             Taylor      86  \n",
       "6816                    Naked As We Can      86  \n",
       "6817                            Fantasy      86  \n",
       "6818                           Epilogue      86  \n",
       "6819                           Groovin'      86  \n",
       "\n",
       "[6820 rows x 11 columns]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cassandra_df = cassandra_dataframe(data)\n",
    "cassandra_df.connect_cassandra()\n",
    "cassandra_df.create_cassandra_keyspace('event')\n",
    "cassandra_df.set_cassandra_keysapce('event')\n",
    "cassandra_df.create_cassandra_table('music_app_history', pk=['sessionId', 'itemInSession'])\n",
    "cassandra_df.insert_df_2_cassandra_table('music_app_history')\n",
    "cassandra_df.cassandra_query_2_df(query=\"select * from music_app_history\")\n",
    "# cassandra_df.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## TO-DO: Assign the INSERT statements into the `query` variable\n",
    "        query = \"insert into music_app_history (artist, firstName, gender, itemInSession, lastName, length, level, location, sessionId, song, userId)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "        ## TO-DO: Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        ## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]`\n",
    "        session.execute(query, ( [line[0], line[1], line[2], int(line[3]),line[4], float(line[5]),line[6],line[7], int(line[8]),line[9], int(line[10])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sessionid', 'iteminsession', 'artist', 'firstname', 'gender', 'lastname', 'length', 'level', 'location', 'song', 'userid'])\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Add in the SELECT statement to verify the data was entered into the table\n",
    "from cassandra.query import dict_factory\n",
    "query = \"select * from music_app_history\"\n",
    "try:\n",
    "    session.row_factory = dict_factory\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(rows.one().keys())\n",
    "# for row in rows:\n",
    "#     print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[415], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/frame.py:1760\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for orient parameter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1756\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morient\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1757\u001b[0m     )\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1762\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py:645\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m--> 645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[1;32m    648\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "query = \"select artist, song, length from music_app_history where sessionId=338 and itemInSession=4\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COPY AND REPEAT THE ABOVE THREE CELLS FOR EACH OF THE THREE QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"DROP TABLE IF EXISTS music_app_history \"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS music_app_history \"\n",
    "query = query + \"(artist text, firstName text, gender text, itemInSession int, lastName text, length float, level text, location text, sessionId int, song text, userId int, PRIMARY KEY (sessionId, userid))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## TO-DO: Assign the INSERT statements into the `query` variable\n",
    "        query = \"insert into music_app_history (artist, firstName, gender, itemInSession, lastName, length, level, location, sessionId, song, userId)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "        ## TO-DO: Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        ## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]`\n",
    "        session.execute(query, ( line[0], line[1], line[2], int(line[3]), line[4], float(line[5]),line[6],line[7], int(line[8]),line[9], int(line[10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Lonnie Gordon', song='Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', firstname='Sylvie', lastname='Cruz')\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "query = \"select artist, song, firstName, lastName from music_app_history where sessionId=182 and userid=10\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print (row)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"DROP TABLE IF EXISTS music_app_history \"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS music_app_history \"\n",
    "query = query + \"(artist text, firstName text, gender text, itemInSession int, lastName text, length float, level text, location text, sessionId int, song text, userId int, PRIMARY KEY (song, sessionId))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## TO-DO: Assign the INSERT statements into the `query` variable\n",
    "        query = \"insert into music_app_history (artist, firstName, gender, itemInSession, lastName, length, level, location, sessionId, song, userId)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "        ## TO-DO: Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        ## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]`\n",
    "        session.execute(query, ( line[0], line[1], line[2], int(line[3]), line[4], float(line[5]),line[6],line[7], int(line[8]),line[9], int(line[10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='The Black Keys', song='All Hands Against His Own', firstname='Sara', lastname='Johnson')\n",
      "Row(artist='The Black Keys', song='All Hands Against His Own', firstname='Jacqueline', lastname='Lynch')\n",
      "Row(artist='The Black Keys', song='All Hands Against His Own', firstname='Tegan', lastname='Levine')\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "query = \"select artist, song, firstName, lastName from music_app_history where song='All Hands Against His Own'\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print (row)   \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Drop the table before closing out the sessions\n",
    "query = \"DROP TABLE IF EXISTS music_app_history \"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
